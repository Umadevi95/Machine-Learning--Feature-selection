{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5f5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449206e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def selectkbest(indep_X, dep_Y, n):\n",
    "    test = SelectKBest(score_func=chi2, k=n)\n",
    "    fit1 = test.fit(indep_X, dep_Y)\n",
    "    selectk_features = fit1.transform(indep_X)\n",
    "    return selectk_features\n",
    "\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to train various classifiers and calculate feature importance\n",
    "def train_and_get_feature_importance(classifier, X_train, y_train):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    if hasattr(classifier, 'feature_importances_'):\n",
    "        return classifier.feature_importances_\n",
    "    elif hasattr(classifier, 'coef_'):\n",
    "        return np.abs(classifier.coef_[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_feature_importance(X_train, y_train, X_test, selected_features):\n",
    "    classifiers = {\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"SVM Linear\": SVC(kernel='linear'),\n",
    "        \"SVM Non-linear\": SVC(kernel='rbf'),\n",
    "        \"KNN\": KNeighborsClassifier()\n",
    "    }\n",
    "    \n",
    "    feature_importances_dict = {}\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        feature_importances = train_and_get_feature_importance(clf, X_train, y_train)\n",
    "        if feature_importances is not None:\n",
    "            feature_importances_dict[clf_name] = feature_importances\n",
    "            \n",
    "            # Sort feature importances in descending order\n",
    "            indices = np.argsort(feature_importances)[::-1]\n",
    "    \n",
    "            # Print feature ranking\n",
    "            print(f\"\\nFeature ranking for {clf_name}:\")\n",
    "            for f in range(selected_features.shape[1]):\n",
    "                print(\"%d. feature %d (%f)\" % (f + 1, indices[f], feature_importances[indices[f]]))\n",
    "    \n",
    "    # Return feature importances\n",
    "    return feature_importances_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e166a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature ranking for Random Forest:\n",
      "1. feature 2 (0.489312)\n",
      "2. feature 0 (0.216364)\n",
      "3. feature 1 (0.176700)\n",
      "4. feature 3 (0.117624)\n",
      "\n",
      "Feature ranking for Logistic Regression:\n",
      "1. feature 2 (3.517234)\n",
      "2. feature 0 (1.858775)\n",
      "3. feature 1 (1.007374)\n",
      "4. feature 3 (0.443108)\n",
      "\n",
      "Feature ranking for Decision Tree:\n",
      "1. feature 2 (0.640780)\n",
      "2. feature 3 (0.138889)\n",
      "3. feature 0 (0.134131)\n",
      "4. feature 1 (0.086200)\n",
      "\n",
      "Feature ranking for SVM Linear:\n",
      "1. feature 2 (4.598870)\n",
      "2. feature 0 (1.317196)\n",
      "3. feature 1 (0.866651)\n",
      "4. feature 3 (0.230976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\aiml\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\anaconda\\envs\\aiml\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\anaconda\\envs\\aiml\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\anaconda\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset1 = pd.read_csv(\"prep.csv\", index_col=None)\n",
    "df2 = pd.get_dummies(dataset1, drop_first=True)\n",
    "indep_X = df2.drop('classification_yes', axis=1)\n",
    "dep_Y = df2['classification_yes']\n",
    "\n",
    "# Perform SelectKBest feature selection\n",
    "selected_features = selectkbest(indep_X, dep_Y, 4)\n",
    "\n",
    "# Split and scale dataset\n",
    "X_train, X_test, y_train, y_test = split_scalar(selected_features, dep_Y)\n",
    "\n",
    "# Calculate and print feature importance for various classifiers\n",
    "feature_importances_dict = calculate_feature_importance(X_train, y_train, X_test, selected_features)\n",
    "\n",
    "# Convert feature importances into DataFrame\n",
    "feature_importances_df = pd.DataFrame(feature_importances_dict).T  # Transpose DataFrame\n",
    "feature_importances_df.index = indep_X.columns  # Set index to column names\n",
    "\n",
    "# Display feature importances DataFrame\n",
    "print(\"\\nFeature importances DataFrame:\")\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee378d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
